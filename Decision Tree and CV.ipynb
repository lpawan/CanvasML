{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)\tHow decision tree works for a regression problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree builds regression or classification models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets. The final result is a tree with decision nodes and leaf nodes. A decision node has two or more branches, each representing values for the attribute tested. Leaf node represents a decision on the numerical target. The topmost decision node in a tree which corresponds to the best predictor called root node. Decision trees can handle both categorical and numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)\tWhy Recursive binary splitting is called Greedy Approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A greedy approach is used to divide the space called recursive binary splitting. This is a numerical procedure where all the values are lined up and different split points are tried and tested using a cost function. The split with the best cost (lowest cost because we minimize cost) is selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)\tWhat do you understand by Greedy approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greedy is an algorithmic paradigm that builds up a solution piece by piece, always choosing the next piece that offers the most obvious and immediate benefit. So the problems where choosing locally optimal also leads to global solution are best fit for Greedy."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4)\tWhat is Pruning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning is used to reduce the size of decision trees by removing parts of the tree that do not provide power to classify instances. Pruning reduces the complexity of the final classifier, and hence improves predictive accuracy by the reduction of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5)\tWhat’s the difference between pre pruning and post pruning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-pruning that stop growing the tree earlier, before it perfectly classifies the training set. Post-pruning that allows the tree to perfectly classify the training set, and then post prune the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6)\tWhat is Entropy? How is it calculated?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy is a measure of inpurity, disorder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7)\tWhat is Gini Impurity?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini Impurity is a measurement of the likelihood of an incorrect classification of a new instance of a random variable, if that new instance were randomly classified according to the distribution of class labels from the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8)\tWhat do you understand by Information Gain? How does it help in tree building?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information gain is the change in information entropy. Decision Trees algorithm will always tries to maximize Information gain. An attribute with highest Information gain will tested/split first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9)\tHow does node selection take place while building a tree?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A node with highest Information gain will be split first. When a predictor is numeric, if all values are unique, there are n – 1 split points for n data points. When a predictor is categorical we can decide to split it to create either one child node per class (multiway splits) or only two child nodes (binary split)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10)\tWhat are different algorithms available for decision tree?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree algorithm can be used for solving regression and classification problems. The goal of using a Decision Tree is to create a training model that can use to predict the class or value of the target variable by learning simple decision rules inferred from training data. The algorithm selection is also based on the type of target variables. Common algorithms used in Decision Trees:\n",
    "ID3 → (extension of D3)\n",
    "C4.5 → (successor of ID3)\n",
    "CART → (Classification And Regression Tree)\n",
    "CHAID → (Chi-square automatic interaction detection Performs multi-level splits when computing classification trees)\n",
    "MARS → (multivariate adaptive regression splines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11)\tWhat’s the main difference between Gini Impurity and Entropy on the basis of computation time?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini is intended for continuous attributes, and Entropy for attributes that occur in classes. Gini will tend to find the largest class, and entropy tends to find groups of classes that make up ~50% of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12)\tWhat are the disadvantages and advantages of using a Decision Tree?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages:\n",
    "Compared to other algorithms decision trees requires less effort for data preparation during pre-processing.\n",
    "A decision tree does not require normalization of data.\n",
    "A decision tree does not require scaling of data as well.\n",
    "Missing values in the data also does NOT affect the process of building decision tree to any considerable extent.\n",
    "A Decision trees model is very intuitive and easy to explain to technical teams as well as stakeholders.\n",
    "\n",
    "Disadvantage:\n",
    "A small change in the data can cause a large change in the structure of the decision tree causing instability.\n",
    "For a Decision tree sometimes calculation can go far more complex compared to other algorithms.\n",
    "Decision tree often involves higher time to train the model.\n",
    "Decision tree training is relatively expensive as complexity and time taken is more.\n",
    "Decision Tree algorithm is inadequate for applying regression and predicting continuous values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13)\tHow do you deploy model in Heroku?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After installing the Heroku CLI, Open a command prompt window and navigate to your project folder.\n",
    "* Type the command **heroku login** to login to your heroku account.\n",
    "* After logging in to Heroku, enter the command **heroku create** to create a heroku app. It will give you the URL of your Heroku app after successful creation. Or alternatively, you can go to the heroku website and create an app directly.\n",
    "* Before deploying the code to the Heroku cloud, we need to commit the changes to the git repository.\n",
    "* Type the command **git init** to initialize a local git repository.\n",
    "* Enter the command **git status** to see the uncommitted changes.\n",
    "* Enter the command **git add .** to add the uncommitted changes to the local repository.\n",
    "* Enter the command **git commit -am \"make it better\"** to commit the changes to the local repository.\n",
    "* Enter the command **git push heroku master** to push the code to the heroku cloud.\n",
    "* After deployment, heroku gives you the URL to hit the web API.\n",
    "* Once your application is deployed successfully, enter the command **heroku logs --tail** to see the logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14)\tWhat challenges you faced while deploying the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)\tWhat is Cross validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a technique in which we train our model using the subset of the data-set and then evaluate using the complementary subset of the data-set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)\tWhy do we need to implement Cross validation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cant be sure that the model will have the desired accuracy and variance in production environment. We need some kind of assurance of the accuracy of the predictions that our model is putting out. For this, we need to validate our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)\tWhat are different types of CV methods?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Hold Out Method approach. \n",
    "2. K-Folds Cross Validation.\n",
    "3. Leave One Out CV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4)\tHow bias and variance varies for each CV method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5)\tIs Train Test Split a kind of CV? True or False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "6)\tHow can we check over fitting using CV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting occurs when the model or the algorithm fits the data too well. Overfitting a model result in good accuracy for training data set but poor results on new data sets. Such a model is not of any use in the real world as it is not able to predict outcomes for new cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
